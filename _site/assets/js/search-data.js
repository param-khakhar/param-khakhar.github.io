var store = [{
        "title": "Data Science, What?",
        "excerpt":" Data Science is an inter-disciplinary field which is used to gain insights into data through computation, statistics and visualization. Inter-disciplinary as in, The stuff present in the background are the popular softwares and frameworks use to carry out different tasks. Tasks such as? It turns out that, the entire process of gaining insights from the data comprises of several smaller sub tasks such as (Detailed Info in the respective articles): Ask an interesting question Here the question refers the task which you want to achieve in the end. It could be either be prediction or estimation of a variable depending on the past trends, it could also be a particular business question which you want to find an answer of like consumer resoponse for a particular product, grouping of consumers for different products etc. Get the Data In order to derive insigts, you would certainly need the data in the first place! Well, you yourself might be collecting the data so that you would use it now. It may also be the case that you want to use the data collected by others and in that scenario you may scrape the data either from web sites, APIs, online repositories etc. While getting the data you also need have to take care about how the data is sampled, or if there are any privacy issues which you might unintentionally violate. Also you need to take care about the relevance of the data you are using. After getting the data you may also need to clean the data. Cleaning as in if there are partially filled entries you may want to remove them. If the datatypes in the data are inconsistent you’d correct it. Exploratory Data Analysis The most important task among all the tasks! Well EDA is getting all about getting a flavor of the data which you’d be using. EDA involves usage of visualization techniques in order to find out any anomalies or patterns in the data. You can do so by checking the different statistical measures such as mean, std, median etc. Certaing modeling techniques (to be discussed afterwards) also involve removal of highly correlated features (in other words those features which significantly depend on each other). The removal of correlated features and also the selection of relevant features to be used for modeling purposes. Model the data This is the task about which you may hear in various articles as “Machine Learning”, “Neural Networks”, “Regression”, “Classifiers” etc. Now, Machine Learning is a sub-field of CS which comprises of algorithms which improve their performance with data. Here the performance may refer to predicting a dependent variable given the values of several independent variables, grouping the data based by finding certain common features, take a decision etc. Such algorithms are known as learning algorithms, this is because in a way the algorithm learns the relation between the dependent and independent variables. These learning algorithms when trained with data. The learning algorithms require data to update their hypothesis relation in order to make better predictions. This is known as the training of the model. Communicate and Visualize the results After you are done with the model forming part, you would certainly want to use it for the prediction of some other stuff. We need to make certain sanity checks whether the predictions made are sound enough or not. In this task you’d prefer to use certain visualization tools. So we use visualizations firstly for EDA and secondy for communicating the results. Well turns out that there’s so much buzz in the media about this, and one of the reasons for this is,   Data Scientist is the sexiest jobs of the 21st Century.   Harvard Business Review &mdash;You can check this Harvard Business Review article. Is it really the case?   I am a data scientist…I don’t find my job sexy.I am 40% a vacuum, another 40% a janitor.And the last 20%… A fortune-teller.   Jingles (Hong jing) &mdash;You can check this article as well by Jingles (Hong jing). Well, there are opinions but, I really find it cool! Finally the roadmap!  References:   CS109 Data Science, Harvard University","categories": ["Data Science"],
        "tags": ["Intro","Data Science","What"],
        "url": "/data%20science/intro-data-science/"
      },{
        "title": "Why is statistics such a fascinating subject?",
        "excerpt":" The world is certainly uncertain, and statistics is a subject to estimate this uncertainity! Yes, no other field of study can deal with such uncertainity, there are always certain assumptions. In this and some of the following articles I’d write about some of the aspects of statistics the knowledge of whose can very much help to better understand the numbers, claims, etc. which are made by people. By the way these articles actually are my notes of the book “A Panorama of Statistics”. If you are even more interested, you better read the entire book. Statistical thinking can certainly help you in making wiser decisions, understand and judge the trustworthyness of different personel, and help you become better citizens, consumers, voters, etc. Even in academics, most subjects involve the study of chance events and as a result you need to know the knowledge of statistics. So even it’d help you become better academicians!   being a statistician [means] you get to play in everyone’s backyard.   [John Turkey]() &mdash;In order to better understand the process of statistical analysis, suppose that you yourself are a statistician at a company and you have collected data for the number of employees that are absent on a given day in a company. You have collected the daily records for over 30 weeks. Now probably you would look for some patterns and even before that wonder what patterns might even exist. A simple organization such as grouping the number of absentees by days of the week may give you some insights. Doing that you notice that Mondays and Fridays are the days which have higher number of employees absent then the other days on average and also you can group the days of the week in two with Monday and Friday in one and the rest all weekdays in the other. Creating different summaries of the data is known as statistical description. You may also use certain visualization techniques in order to discover some pattern. Other than methods used for statistical description, there are also methods which the statisticians can use in order to generalize the detected patterns in a wider setting. This is known as statistical inference. Now what makes this valueable is that this comes with an objective measure of the likelihood that it is correct. However, we can never by sure that a generalization is correct, because uncertainity is so pervasive in the real world. Now returning to your original task, your hypothesis of higher absence rates on Monday and Fridays can statistically tested and we can also obtain the uncertainity of it being correct. The alternate hypothesis would then be that the data obtained is just by chance and no such concrete generalization exists. Interestingly, the wider setting in the generalization can also refer to future and in a way we can predict future! (with some uncertainity). If your hypothesis turns out to be correct you can certainly notify the board and go home. Now, all the above stuff may seem to be paradoxical as what are the rules which you use to make predictions about the future given the uncertainities of the world. The thing is that statistics involves logic rules which are different from the traditional mathematics. Essentially, statistical description and statistical inference are the workday roles of statistics. There are several other byways, some of which are also aren’t discussed in the curriculum such as:   Paradoxes of probability and statistics  Problems of using standard statistical techniques in non-standard situations.  Social Impact of StatisticsHow Statistics is different from Mathematics?       Turns out that statisticians solve the problem in a real life setting in contrast to mathematicians. Mathematical problems, abstracts out from all the uncertainity and fthen proceeds to report a unique solution. However, when we incorporate chances to play their role, the solution derived from maths is simply an approximation from the true value. Statisticians also calculate an answer and that too is an approximation but with the answer, a statistician also reports an uncertainity. Thus, the answer would be good only if the uncertainity is less.         Mathematicians also need data and they plug it in some general theorem and hence obtain the result. However, statisticians proceed the other way round. They are given a particular sample of information (from the entire population) and their job is to estimate the population from the obtained sample. Thus, for mathematicians data refers to the values of non-random variables whereas for statisticians, data refers to the values of random variables. Consequently, statisticians would have to take care about erroneous data which might be present in the example which they have.   Trivia Consider 3 cities A,B and C. The annual average temperatures (in degree Celsius) are 11.7, 25.2 and 27 respectively. Can we infer from this information that B is twice as hot as A in a year? Also would it be correct to say that B and C have similar temperatures throughout the year? Well, No. The thing is we can’t and we shouldn’t limit ourselves to the comparisons of the annual means. It may turn out that during some months B is slightly hotter than A but that trend is not preserved throughout the year. Also it might turn out that B and C have significantly different temperatures throughout a particular month. It often turns out that the byways are often more interesting then the stuff discussed in the curriculum, so stay tuned. Image References:   A Panorama of Statistics  ","categories": ["Statistics"],
        "tags": ["Intro","Statistics"],
        "url": "/statistics/intro-stats/"
      },{
        "title": "Statistics is indeed paradoxical!",
        "excerpt":" Consider the following situation, You are looking for a hospital for the treatment of someone elderly in your family. There are two prominent choices available, Hospital A and Hospital B. For the last 1000 patients those which got treated from Hospital A had a survival rate of 90% whereas those which got treated from Hospital B had survival rate of 80%. So, Hospital A seems to be a clear winner right? Well it may not be the case. One shouldn’t ignore the fact that all the patients which arrive at the hospital do not have same health level. For example we can classify the patients having good health and bad health repectively. Let the number of survival rates of the patients considering the above classification scheme be as follows:   Hospital A - 900 in good health out of which 830 survived, 100 in poor health out of which 30 survived  Hospital B - 600 in good health out of which 590 survived, 400 in poor health out of which 210 survivedInterestingly, the survival rates of the patients having poor health is 52.5% in B and 30% in A. Amazingly, the survival rates of the patients having good health for Hospital A is 92.22 % whereas the same for Hospital B is 98.33%. Turns out that Hospital B is a clear winner and that too convincingly. The above is an example of Simpson’s paradox which occurs when the aggregated data hides a conditional variable, which is hidden additional factor that significantly influences results.   Statistics are persuasive. So much so that people, organizations, and whole countries base some of their most important decisions on organized data. But any set of statistics might have something lurking inside it that can turn the results completely upside down.   Mark Liddel &mdash; Ted-Ed, How statistics can be misleadingSimpson’s paradox isn’t hypothetical. You can look at Mark Liddel’s video for more examples. The above is one of the many things about statistics which I found very fascinating. ","categories": ["Statistics"],
        "tags": ["Paradox","Statistics","Data Science"],
        "url": "/statistics/paradox-stats/"
      }]
